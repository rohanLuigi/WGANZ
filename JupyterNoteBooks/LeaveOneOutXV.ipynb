{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-out-one Cross Validation\n",
    "\n",
    "### November 2015\n",
    "### Rohan Fernando, Emre Karaman, Hao Cheng and Dorian Garrick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training is based on leaving out observation $j$ from the training data, for $j=1,\\ldots, n$ \n",
    "* Then, $y_j$ is predicted as $\\hat{y}_j = \\mathbf{x}_j'\\hat{\\beta}$, where $\\hat{\\beta}$ is the estimate of $\\beta$ estimated from the data set where observation $j$ was left out. \n",
    "* Thus, cross validation by straightforward application of this approach, would require $n$ analyses with $n-1$ observations in each analysis. \n",
    "* Fortunately, when the marker effects model (MEM) is used, leave-one-out cross validation can be performed with little more effort than is required for a single analysis with $n$ observations by using a well-known strategy used in least-squares regression to compute the predicted residual sum of squares (PRESS) statistic. \n",
    "* When $k>n$ the breeding value model (BVM) is more efficient because for this model the mixed model equations are of order $n\\times n$. \n",
    "* We show below how leave-one-out cross validation can also be performed using either or the MEM and BVM with little more effort than is required for a single analysis with $n$ observations. Dan Gianola is also working on this problem, even for the Bayesian alphabet methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker Effects Model\n",
    "Use of the MEM is more efficient when $n>k$ because for this model the mixed model equations are of order $k\\times k$. The MEM for G-BLUP can be written as\n",
    "$$\n",
    "        \\mathbf{y}=\\mathbf{X}\\mathbf{\\beta}+\\mathbf{e},\n",
    "$$\n",
    "where $\\mathbf{y}$ has been corrected for all effects other than $\\mathbf{\\beta}$, the marker effects, and $\\mathbf{X}$ is the matrix of marker covariates. Often it is assumed that marker effects are identically and independetly distributed (iid) random variables with null means and variances $\\sigma^2_\\beta$. Thus, under the usual assumption that the resudual are iid with null means and variances $\\sigma^2_e$, $\\text{E}(\\mathbf{y}) = \\mathbf{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, BLP of $\\beta$\n",
    "can be obtained by solving the $k\\times k$ mixed model equations\n",
    "\n",
    "$$\n",
    "\\left(\\mathbf{X'X}+\\mathbf{I}\\lambda\\right)\\hat{\\mathbf{\\beta}}=\\mathbf{X'y},\n",
    "$$\n",
    "where $\\lambda=\\frac{\\sigma_{e}^{2}}{\\sigma_{\\beta}^{2}}$.\n",
    "\n",
    "Now, BLUP for $\\mathbf{\\beta_{-j}}$, where observation $j$ is\n",
    "left out, can be obtained as\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\beta}}_{-j}=\n",
    "\\left(\\mathbf{X}_{-j}'\\mathbf{X}_{-j}+\\mathbf{I}\\lambda\\right)^{-1}\\mathbf{X}_{-j}'\n",
    "    \\mathbf{y}_{-j},\\label{eq:PRESS1-1} \\tag{1}\n",
    "$$\n",
    "where $\\mathbf{X}_{-j}$ is $\\mathbf{X}$ with the $j$th\n",
    "row removed and $\\mathbf{y}_{-j}$ is $\\mathbf{y}$ with the\n",
    "$j$th element removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, from the matrix inverse lemma,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\left(\\mathbf{X}_{-j}'\\mathbf{X}_{-j}+\\mathbf{I}\\lambda\\right)^{-1} & =\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda-\\mathbf{x}_{j}\\mathbf{x}_{j}^{'}\\right)^{-1}\\nonumber \\\\\n",
    " & =\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}-\\frac{\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}\\mathbf{x}_{j}\\mathbf{x}_{j}^{'}\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}}{1-H_{jj}},\\label{eq:PRESS2-1} \\tag{2}\n",
    "\\end{align} \n",
    "$$\n",
    "where the quadratic $H_{jj}=\\mathbf{x}_{j}^{'}\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}\\mathbf{x}_{j}$\n",
    "is the $j$th diagonal element of $\\mathbf{H}=\\mathbf{X}\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}\\mathbf{X}^{'}$.\n",
    "\n",
    "Using (\\ref{eq:PRESS2-1}) in (\\ref{eq:PRESS1-1}), the prediction\n",
    "residual for the $j$th observation can be written as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{e_{j}} & =y_{j}-\\mathbf{x}_{j}^{'}\\hat{\\mathbf{\\beta}}_{-j}\\\\\n",
    " & =y_{j}-\\mathbf{x}_{j}^{'}\\left[\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}-\\frac{\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}\\mathbf{x}_{j}\\mathbf{x}_{j}^{'}\\left(\\mathbf{X}'\\mathbf{X}+\\mathbf{I}\\lambda\\right)^{-1}}{1-H_{jj}}\\right]\\mathbf{X}_{-j}'\\mathbf{y}_{-j}\\\\\n",
    " & =\\frac{y_{j}-\\mathbf{x}_{j}^{'}\\hat{\\mathbf{\\beta}}}{1-H_{jj}}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then PRESS is calculated as $\\sum_{j=1}^{n}\\hat{e_{j}}^{2}$. \n",
    "The accuracy\n",
    "of genomic prediction is often quantified as the correlation between\n",
    "the predicted and observed values of $y_{j}$, and this correlation\n",
    "can be estimated from the values of $\\hat{y}_{j}$ efficiently computed\n",
    "as $\\hat{y}_{j}=y_{j}-\\hat{e}_{j}$ and the observed values of $y_{j}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simDat (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "function simDat(nObs,nLoci,bMean,bStd,resStd)\n",
    "    X = sample([0;1;2],(nObs,nLoci))\n",
    "    b = rand(Normal(bMean,bStd),size(X,2))\n",
    "    y = X*b + rand(Normal(0.0, resStd),nObs)\n",
    "    return (y,X,b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nObs,nLoci,bMean,bStd,resStd = 5,10,0.0,1.0,1.0\n",
    "res = simDat(nObs,nLoci,bMean,bStd,resStd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5x10 Array{Int64,2}:\n",
       " 0  0  1  0  1  0  0  2  0  0\n",
       " 2  0  1  2  2  0  0  1  1  2\n",
       " 0  2  2  0  2  0  2  0  2  2\n",
       " 1  2  0  1  1  1  2  0  0  0\n",
       " 1  1  0  2  2  1  2  1  2  1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = res[1]\n",
    "X = res[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inefficient Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOjEHat (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LOjEHat(X,y,vara,vare,j)\n",
    "    位 = vare/vara\n",
    "    n = size(X,1)\n",
    "    k = size(X,2)\n",
    "    xPj = X[j,:]\n",
    "    yj  = y[j]\n",
    "    sel = fill(true,n)\n",
    "    sel[j] = false\n",
    "    X = X[sel,:]\n",
    "    y = y[sel]\n",
    "    betaHat = inv(X'X + eye(k)*位)*X'y\n",
    "    return yj - xPj*betaHat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vara = 1.0/size(X,2)\n",
    "vare = 1.0\n",
    "eHatN = [LOjEHat(X,y,vara,vare,j) for j=1:nObs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " [-1.4699853883814626]\n",
       " [5.243389656376071]  \n",
       " [3.1269790819277348] \n",
       " [0.6267327037778616] \n",
       " [-2.102125836625234] "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eHatN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 44.2437"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eHatN'eHatN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5x5 Array{Float64,2}:\n",
       "  0.330849    0.0866482   0.0405644  -0.0310075   0.035482\n",
       "  0.0866482   0.513184    0.0752436  -0.00833613  0.188767\n",
       "  0.0405644   0.0752436   0.582424    0.0920299   0.138256\n",
       " -0.0310075  -0.00833613  0.0920299   0.40272     0.19174 \n",
       "  0.035482    0.188767    0.138256    0.19174     0.435922"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "位 = vare/vara\n",
    "H = X*inv(X'X + eye(nLoci)*位)*X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -1.46999 \n",
       "  5.24339 \n",
       "  3.12698 \n",
       "  0.626733\n",
       " -2.10213 "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 1 - diag(H)\n",
    "eHat = (y - H*y) ./ d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 44.2437"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eHat'eHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of prediction: cor($y$,$\\hat{y}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 1.25787\n",
       " 1.68008\n",
       " 2.45931\n",
       " 1.51281\n",
       " 4.40005"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat = y - eHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04062265289091238"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor(y,yHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breeding Value Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BVM for G-BLUP is \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{y} & =\\mathbf{u}+\\mathbf{e},\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\mathbf{u}=\\mathbf{X}\\mathbf{\\beta}$,  $\\text{Var}\\left(\\mathbf{u}\\right)=\\mathbf{XX'}\\sigma_{\\beta}^{2}$,\n",
    "and all other variables are as in the MEM.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute PRESS efficiently using the BVM, we first construct the matrix $\\mathbf{\\mathbf{Q}}$ by augmenting the\n",
    "covariance matrix $\\mathbf{V=X}\\mathbf{X}'\\sigma_{\\beta}^{2}+\\mathbf{I}\\sigma_{e}^{2}$\n",
    "with one leading row and column as\n",
    "$$\n",
    "\\mathbf{Q}=\\begin{bmatrix}\\mathbf{y'y} & \\mathbf{y^{'}}\\\\\n",
    "\\mathbf{y} & \\mathbf{V}\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the prediction residual for observation $j,$ the second\n",
    "row and column of $\\mathbf{Q}$ are permuted with row and column $1+j$.\n",
    "This permuted $\\mathbf{Q}$ can be written as $\\mathbf{P}_{j}\\mathbf{Q}\\mathbf{P}_{j}=\\mathbf{W}$,\n",
    "where the permutation matrix $\\mathbf{P}_{j}$ is obtained by permuting\n",
    "the second row of the $n\\times n$ identity matrix with row $1+j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical example to demonstrate $\\mathbf{P}_{j}\\mathbf{Q}\\mathbf{P}_{j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4x4 Array{Int64,2}:\n",
       "  1   2   3   4\n",
       "  5   6   7   8\n",
       "  9  10  11  12\n",
       " 13  14  15  16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q for the example\n",
    "Q = [ 1  2  3  4\n",
    "      5  6  7  8\n",
    "      9 10 11 12\n",
    "     13 14 15 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make P to permute row and column 2 with row and column 3 of $\\mathbf{Q}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get $\\mathbf{P}$ by permuting row 2 and 3 of identity matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4x4 Array{Float64,2}:\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4x4 Array{Float64,2}:\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "j = 3\n",
    "P[i,:],P[j,:] = P[j,:],P[i,:]\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4x4 Array{Float64,2}:\n",
       "  1.0   2.0   3.0   4.0\n",
       "  9.0  10.0  11.0  12.0\n",
       "  5.0   6.0   7.0   8.0\n",
       " 13.0  14.0  15.0  16.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = P*Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4x4 Array{Float64,2}:\n",
       "  1.0   3.0   2.0   4.0\n",
       "  9.0  11.0  10.0  12.0\n",
       "  5.0   7.0   6.0   8.0\n",
       " 13.0  15.0  14.0  16.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R*P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the permuted $\\mathbf{Q}$ matrix is:\n",
    "\n",
    "$$\n",
    "\\mathbf{W}=\\left[\\begin{array}{ccc}\n",
    "\\mathbf{y'y} & y_{j} & \\mathbf{y}_{-j}^{'}\\\\\n",
    "y_{j} & V_{jj} & \\mathbf{V}_{j,-j}\\\\\n",
    "\\mathbf{y}_{-j} & \\mathbf{V}_{-j,j} & \\mathbf{V}_{-j,-j}\n",
    "\\end{array}\\right]=\\begin{bmatrix}\\mathbf{\\mathbf{A}} & \\mathbf{\\mathbf{B}'}\\\\\n",
    "\\mathbf{\\mathbf{B}} & \\mathbf{\\mathbf{C}}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "where the leading $2\\times2$ matrix is $\\mathbf{A}=\\begin{bmatrix}\\mathbf{y'y} & y_{j}\\\\\n",
    "y_{j} & V_{jj}\n",
    "\\end{bmatrix}$, and the other partitions are: $\\mathbf{B}=\\begin{bmatrix}\\mathbf{y}_{-j}^{'}\\\\\n",
    "\\mathbf{V}_{j,-j}\n",
    "\\end{bmatrix}$ and $\\mathbf{C}=\\mathbf{V}_{-j,-j}$, where $-j$ denotes that the\n",
    "$j$th element, row or column is removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining $\\mathbf{W^{11}}$\n",
    "as the top left or leading $2\\times2$ sub-matrix in $\\mathbf{W}^{-1}$,\n",
    "from partitioned inverse-matrix identities (Searle, 1982), the inverse\n",
    "of $\\mathbf{W}^{11}$ can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "(\\mathbf{W^{11}})^{-1} & =\\mathbf{A}-\\mathbf{B}\\mathbf{C}^{-1}\\mathbf{B^{'}}\\nonumber \\\\\n",
    " & =\\begin{bmatrix}\\mathbf{y'y} & y_{j}\\\\\n",
    "y_{j} & V_{jj}\n",
    "\\end{bmatrix}-\\begin{bmatrix}\\mathbf{\\mathbf{y}_{-j}^{'}}\\\\\n",
    "\\mathbf{V_{j,-j}}\n",
    "\\end{bmatrix}\\mathbf{V}_{-j,-j}^{-1}\\begin{bmatrix}\\mathbf{\\mathbf{y}_{-j}} & \\mathbf{V_{-j,j}}\\end{bmatrix}\\nonumber \\\\\n",
    " & =\\begin{bmatrix}\\mathbf{y}'\\mathbf{y}-\\mathbf{y}_{-j}^{'}\\mathbf{V_{-j,-j}^{-1}}\\mathbf{y}_{-j} & y_{j}-\\mathbf{y}_{-j}^{'}\\mathbf{V}_{-j,-j}^{-1}\\mathbf{V}_{-j,j}\\\\\n",
    "y_{j}-\\mathbf{V_{j,-j}V_{-j,-j}^{-1}\\mathbf{y}_{-j}} & V_{jj}\\mathbf{-V_{j,-j}V_{-j,-j}^{-1}V_{-j,j}}\n",
    "\\end{bmatrix}.\\label{eq:Winverse-1} \\tag{3}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $\\mathbf{V_{j,-j}}$ in element (2,1) of the above inverse\n",
    "matrix is the vector of covariances between $y_{j}$ and $\\mathbf{y}_{-j}$\n",
    "and that $\\mathbf{V_{-j,-j}^{-1}}$is the inverse of the covariance\n",
    "matrix of $\\mathbf{y}_{-j}$. Thus, $\\hat{y}_{j}=V_{j,-j}V_{-j,-j}^{-1}\\mathbf{y}_{-j}$\n",
    "is the BLP of $y_{j}$ given $\\mathbf{y}_{-j}$, and element (2,1)\n",
    "of (\\ref{eq:Winverse-1}) is the prediction residual of $y_{j}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, because the permutation matrix $\\mathbf{P}_{j}$ is orthogonal,\n",
    "$\\mathbf{W}^{-1}=(\\mathbf{P}_{j}\\mathbf{Q}\\mathbf{P}_{j})^{-1}=\\mathbf{P}_{j}\\mathbf{Q}^{-1}\\mathbf{P}_{j}$,\n",
    "and the elements of $\\mathbf{W}^{11}$ that are of interest in terms\n",
    "of predicting individual j can be obtained directly from $\\mathbf{Q}^{-1}$as\n",
    "$$\n",
    "\\mathbf{W}^{11}=\\left[\\begin{array}{cc}\n",
    "q^{1,1} & q^{1,(1+j)}\\\\\n",
    "q^{(1+j),1} & q^{(1+j),(1+j)}\n",
    "\\end{array}\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It follows that $\\hat{e}_{j}$, which is the the offdiagonal element\n",
    "of the inverse of the $2\\times2$ matrix $\\mathbf{W}^{11}$, can be\n",
    "written in terms of $\\mathbf{Q}^{-1}$ as \n",
    "\\begin{equation}\n",
    "\\hat{e}_{j}=\\frac{-q^{(1+j),1}}{q^{1,1}q^{(1+j),(1+j)}-q^{1,(1+j)}q^{(1+j),1}},\\label{eq:yhat} \\tag{4}\n",
    "\\end{equation}\n",
    "where $q^{i,j}$ is the element from row $i$ and column $j$ of $\\mathbf{Q}^{-1}$.\n",
    "Thus, once $\\mathbf{Q}^{-1}$ is computed, $\\hat{e}_{j}$ for all\n",
    "$j$ can be computed using (\\ref{eq:yhat}), and these values can\n",
    "be used to compute PRESS as $\\sum_{j=1}^{n}\\hat{e_{j}}^{2}$. To estimate\n",
    "the correlation between the predicted and observed values of $y_{j},$\n",
    "the value of $\\hat{y}_{j}$ is efficiently computed as $\\hat{y}_{j}=y_{j}-\\hat{e}_{j}.$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6x6 Array{Float64,2}:\n",
       " 89.0442    -0.212117  6.92347  5.58629  2.13955  2.29793\n",
       " -0.212117   1.6       0.5      0.4      0.1      0.4    \n",
       "  6.92347    0.5       2.9      1.2      0.6      1.5    \n",
       "  5.58629    0.4       1.2      3.4      1.0      1.6    \n",
       "  2.13955    0.1       0.6      1.0      2.2      1.2    \n",
       "  2.29793    0.4       1.5      1.6      1.2      3.1    "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = vara*X*X' + vare*eye(size(X,1))\n",
    "Q = [y'y y'\n",
    "     y   V]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOjEHat (generic function with 2 methods)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LOjEHat(Q,j)\n",
    "    Qi = inv(Q)\n",
    "    eHatj = -Qi[1+j,1]/(Qi[1,1]*Qi[1+j,1+j] - Qi[1,1+j]*Qi[1+j,1])\n",
    "    return eHatj\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eHatQ = [LOjEHat(Q,j) for j=1:nObs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040622652890912776"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHatQ = y - eHatQ\n",
    "cor(y,yHatQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5x2 Array{Any,2}:\n",
       " -1.46999   -1.46999 \n",
       "  5.24339    5.24339 \n",
       "  3.12698    3.12698 \n",
       "  0.626733   0.626733\n",
       " -2.10213   -2.10213 "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[eHatQ eHat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Give the matrix $\\mathbf{P}_5$ that can be used to permute the second row and column of $\\mathbf{Q}$ with row and column $5+1$\n",
    "2. Observe that $\\mathbf{P}_5$ = $\\mathbf{P}_5'$\n",
    "2. Observe that $\\mathbf{P}_5$ = $\\mathbf{P}^{-1}_5$\n",
    "2. Use this matrix to compute $\\mathbf{W}$.\n",
    "3. Compute $\\hat{e}_5$ from $\\mathbf{W}^{-1}$\n",
    "4. Compute $\\hat{e}_5$ from $\\mathbf{Q}^{-1}$\n",
    "5. Compute $\\hat{e}_5$ by training on the first four observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without Pre-corrected Data\n",
    "\n",
    "Here, we consider the situation where $\\mathbf{y}$ has not been pre-corrected for non-marker effects, which may be fixed or random. Thus, now the model may contain both fixed and random effects, and the vector $\\mathbf{\\beta}$ of location parameters can be partitioned as  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\beta} = \\begin{bmatrix} \n",
    "                      \\mathbf{\\beta}_1 \\\\\n",
    "                      \\mathbf{\\beta}_2\n",
    "                 \\end{bmatrix},\n",
    "$$                 \n",
    "where $\\mathbf{\\beta}_1$ contains all the fixed effects and the vector $\\mathbf{\\beta}_2$ contains all the random effects. This situation does not pose any difficulty for computing PRESS efficiently using the MEM, where now the model for $\\mathbf{y}$ is:\n",
    "\n",
    "$$\n",
    "        \\mathbf{y}=\\mathbf{X}_1\\mathbf{\\beta}_1 + \\mathbf{X}_2\\mathbf{\\beta}_2 + \\mathbf{e},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $\\text{E}(\\mathbf{y}) = \\mathbf{X}_1\\mathbf{\\beta}_1$ and $\\text{Var}(\\mathbf{y}) = \n",
    "\\mathbf{X}_2\\text{Var}(\\mathbf{\\beta}_2)\\mathbf{X}_2'$. As the phenotypic values now do not have null means, predictions from the mixed model equations are BLUPs and not BLPs.  \n",
    "\n",
    "In order to compute PRESS efficiently when $n < k$, using the BVM, note that the mixed model equations \n",
    "that correspond to this mixed model can be derived by treating $\\mathbf{\\beta}_1$ as \"random\" with null mean and very large variances. So, let "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Var}(\\mathbf{\\beta}) = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{I}_1\\sigma^2_L & \\mathbf{0} \\\\\n",
    "\\mathbf{0}             & \\text{Var}(\\mathbf{\\beta}_2) \n",
    "\\end{bmatrix} = \\mathbf{\\Sigma},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for some sufficiently large value of $\\sigma^2_L$. Then under this assumption, $\\text{E}(\\mathbf{y}) = \\mathbf{0}$ and \n",
    "$\\text{Var}(\\mathbf{y}) = \\mathbf{X\\Sigma X}' = \\mathbf{V}$, and thus, \n",
    "\n",
    "$$\n",
    "\\hat{y}_{j}=V_{j,-j}V_{-j,-j}^{-1}\\mathbf{y}_{-j}\n",
    "$$\n",
    "\n",
    "is the BLP of $y_{j}$ given $\\mathbf{y}_{-j}$. But, this BLP will be numerically very close to the value of BLUP obtained from the mixed model equations for the model with fixed $\\mathbf{\\beta}_1$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5x12 Array{Int64,2}:\n",
       " 1  0  0  0  1  0  1  0  0  2  0  0\n",
       " 1  0  2  0  1  2  2  0  0  1  1  2\n",
       " 0  1  0  2  2  0  2  0  2  0  2  2\n",
       " 0  1  1  2  0  1  1  1  2  0  0  0\n",
       " 0  1  1  1  0  2  2  1  2  1  2  1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariates for fixed effects\n",
    "X1 = [\n",
    "1  0\n",
    "1  0\n",
    "0  1\n",
    "0  1\n",
    "0  1  \n",
    "]\n",
    "X2 = res[2]   # same marker covariates as before\n",
    "X  = [X1 X2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from BVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6x6 Array{Float64,2}:\n",
       " 89.0442    -0.212117   6.92347         5.58629         2.13955    2.29793  \n",
       " -0.212117   1.00002e5  1.00001e5       0.4             0.1        0.4      \n",
       "  6.92347    1.00001e5  1.00003e5       1.2             0.6        1.5      \n",
       "  5.58629    0.4        1.2             1.00003e5  100001.0        1.00002e5\n",
       "  2.13955    0.1        0.6        100001.0             1.00002e5  1.00001e5\n",
       "  2.29793    0.4        1.5             1.00002e5       1.00001e5  1.00003e5"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigV = 100000\n",
    "D = diagm([fill(bigV,2); ones(10)*vara])\n",
    "V = X*D*X' + + vare*eye(size(X,1))\n",
    "Q = [y'y y'\n",
    "     y   V]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " -7.14102 \n",
       "  7.14116 \n",
       "  3.42466 \n",
       " -0.422273\n",
       " -2.29318 "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eHatQ = [LOjEHat(Q,j) for j=1:nObs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12x12 Array{Float64,2}:\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0  10.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0  10.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0  10.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0  10.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0  10.0   0.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0   0.0  10.0   0.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0  10.0   0.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  10.0   0.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  10.0   0.0\n",
       " 0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  10.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "位 = vare/vara\n",
    "D = diagm([fill(0.0,2);ones(nLoci)*位])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5x5 Array{Float64,2}:\n",
       "  0.703748     0.296252     0.00338359   0.0597767  -0.0631603\n",
       "  0.296252     0.703748    -0.00338359  -0.0597767   0.0631603\n",
       "  0.00338359  -0.00338359   0.631941     0.164292    0.203767 \n",
       "  0.0597767   -0.0597767    0.164292     0.569157    0.266551 \n",
       " -0.0631603    0.0631603    0.203767     0.266551    0.529682 "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = X*inv(X'X + D)*X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -7.14119 \n",
       "  7.14119 \n",
       "  3.42466 \n",
       " -0.422303\n",
       " -2.29319 "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 1 - diag(H)\n",
    "eHatMEM = (y - H*y) ./ d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5x2 Array{Any,2}:\n",
       " -7.14102   -7.14119 \n",
       "  7.14116    7.14119 \n",
       "  3.42466    3.42466 \n",
       " -0.422273  -0.422303\n",
       " -2.29318   -2.29319 "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[eHatQ eHatMEM]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
